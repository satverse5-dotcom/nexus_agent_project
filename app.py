# app.py
import os
from dotenv import load_dotenv
import streamlit as st
from agent import LangGraphAgent
from gemini_chat import get_gemini_response
from langchain_google_genai import ChatGoogleGenerativeAI
from google.auth import default as google_auth_default

# -----------------------------------------------------
# 0Ô∏è‚É£ Load local .env and Streamlit Secrets for API keys
# -----------------------------------------------------
load_dotenv()  # Load local .env for development
gemini_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
tavily_key = st.secrets.get("TAVILY_API_KEY") or os.getenv("TAVILY_API_KEY")
google_json_path = st.secrets.get("GOOGLE_APPLICATION_CREDENTIALS") or os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

# -----------------------------------------------------
# 0Ô∏è‚É£a Set Google JSON path explicitly from repo
# -----------------------------------------------------
if google_json_path:
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.join(
        os.getcwd(), os.path.basename(google_json_path)
    )

# Set environment variables for LangChain / Google SDK
if gemini_key:
    os.environ["GEMINI_API_KEY"] = gemini_key
if tavily_key:
    os.environ["TAVILY_API_KEY"] = tavily_key

# -----------------------------------------------------
# 1Ô∏è‚É£ Check for credentials / API keys
# -----------------------------------------------------
use_adc = False
try:
    credentials, project = google_auth_default()
    if credentials:
        use_adc = True
except Exception as e:
    st.sidebar.warning(f"ADC not available: {e}")

if not gemini_key and not use_adc:
    st.error("‚ùå Neither GEMINI_API_KEY nor Google ADC credentials found.")
    st.stop()
else:
    st.sidebar.info("‚úÖ Using GEMINI_API_KEY from Secrets/.env or Google ADC")

# -----------------------------------------------------
# 2Ô∏è‚É£ Streamlit Page Setup
# -----------------------------------------------------
st.set_page_config(
    page_title="NexusAgent 2.0",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.title("üöÄ NexusAgent 2.0: Advanced Autonomous AI")
st.markdown(
    """
    Powered by **Google Gemini API**  
    - üß© **Agent Mode (LangGraph)**: Goal-driven autonomous agent  
    - üí¨ **Direct Chat (Gemini 2.5 Flash)**: Simple Q&A chatbot
    """
)

# -----------------------------------------------------
# 3Ô∏è‚É£ Sidebar Mode Switch
# -----------------------------------------------------
mode = st.sidebar.radio(
    "Choose Mode:",
    ["Agent Mode (LangGraph)", "Direct Chat (Gemini 2.5 Flash)"],
)

# -----------------------------------------------------
# 4Ô∏è‚É£ Helper to create Gemini LLM
# -----------------------------------------------------
def create_gemini_llm():
    return ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.7,
        google_api_key=gemini_key  # Always use API key if provided
    )

# -----------------------------------------------------
# 5Ô∏è‚É£ AGENT MODE
# -----------------------------------------------------
if mode == "Agent Mode (LangGraph)":
    st.header("Set a Goal for the Agent")
    user_goal = st.text_input(
        "Enter what you want the agent to accomplish:",
        placeholder="e.g., Summarize the latest AI news."
    )

    if "agent" not in st.session_state:
        try:
            st.session_state.agent = LangGraphAgent(llm=create_gemini_llm())
        except Exception as e:
            st.exception(e)
            st.stop()

    if st.button("Execute Agent"):
        if not user_goal.strip():
            st.warning("‚ö†Ô∏è Please enter a goal for the agent to execute.")
        else:
            st.write("---")
            st.subheader("Agent Execution Log")
            with st.spinner("ü§ñ NexusAgent (Gemini) is working..."):
                try:
                    stream = st.session_state.agent.run(user_goal)
                    final_answer = ""
                    for chunk in stream:
                        agent_data = chunk.get("agent", {})
                        messages = agent_data.get("messages", [])
                        if messages:
                            final_answer = getattr(messages[-1], "content", "")

                    if final_answer:
                        st.success("**Final Answer:**")
                        st.markdown(final_answer)
                    else:
                        st.warning("‚ö†Ô∏è No response generated by the agent.")
                except Exception as e:
                    st.exception(e)

# -----------------------------------------------------
# 6Ô∏è‚É£ DIRECT CHAT MODE
# -----------------------------------------------------
else:
    st.header("üí¨ Direct Gemini Chat")

    with st.form(key="chat_form", clear_on_submit=True):
        user_input = st.text_input("Enter your message:")
        submit_button = st.form_submit_button("Send")

    if submit_button:
        if not user_input.strip():
            st.warning("‚ö†Ô∏è Please enter a message to send.")
        else:
            with st.spinner("‚ú® Gemini is thinking..."):
                try:
                    response_text = get_gemini_response(
                        user_input,
                        model_name="gemini-2.5-flash"
                    )
                    st.success("**Gemini‚Äôs Reply:**")
                    st.markdown(response_text)
                except Exception as e:
                    st.exception(e)
